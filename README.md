# AI Chat Application

A modern, real-time AI chat application built with Next.js frontend and Django backend, featuring streaming responses and a beautiful, professional UI.

## ğŸš€ Features

- **Real-time Chat**: Interactive AI conversations with streaming responses
- **Modern UI**: Clean, professional design with vibrant blue accents
- **Typewriter Effect**: Smooth text animation for AI responses
- **Auto-focus**: Seamless typing experience with automatic input focus
- **Responsive Design**: Works perfectly on desktop and mobile
- **Component Architecture**: Modular, reusable React components
- **TypeScript**: Full type safety throughout the application

## ğŸ—ï¸ Architecture

### Frontend (Next.js 15)

- **Framework**: Next.js 15 with App Router
- **UI Library**: Tailwind CSS with custom styling
- **State Management**: React hooks with TanStack Query
- **Components**: Modular component architecture
- **TypeScript**: Full type safety

### Backend (Django)

- **Framework**: Django with Django REST Framework
- **LLM Integration**: AWS-hosted LLM via external API
- **API**: RESTful endpoints with OpenAPI documentation
- **CORS**: Configured for frontend communication

## ğŸ“ Project Structure

```
pChat/
â”œâ”€â”€ app/                          # Next.js App Router
â”‚   â”œâ”€â”€ components/               # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ ChatContainer.tsx    # Main chat layout
â”‚   â”‚   â”œâ”€â”€ ChatHeader.tsx       # Header with status
â”‚   â”‚   â”œâ”€â”€ ChatMessage.tsx      # Individual message
â”‚   â”‚   â”œâ”€â”€ ChatMessages.tsx     # Messages container
â”‚   â”‚   â”œâ”€â”€ ChatInput.tsx        # Input field
â”‚   â”‚   â”œâ”€â”€ LoadingIndicator.tsx # Loading states
â”‚   â”‚   â””â”€â”€ index.ts             # Component exports
â”‚   â”œâ”€â”€ hooks/                   # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ useChat.hook.ts      # Chat logic and state
â”‚   â”‚   â””â”€â”€ usePostPrompt.hook.ts # API integration
â”‚   â”œâ”€â”€ types/                   # TypeScript interfaces
â”‚   â”‚   â””â”€â”€ chat.ts              # Chat-related types
â”‚   â”œâ”€â”€ schema/                  # API schema
â”‚   â”‚   â”œâ”€â”€ apiClient.ts         # API client setup
â”‚   â”‚   â””â”€â”€ schema.d.ts          # Generated types
â”‚   â”œâ”€â”€ providers/               # React providers
â”‚   â”‚   â””â”€â”€ TanstackQueryClientProvider.tsx
â”‚   â”œâ”€â”€ globals.css              # Global styles
â”‚   â”œâ”€â”€ layout.tsx               # Root layout
â”‚   â””â”€â”€ page.tsx                 # Main page
â”œâ”€â”€ src/                         # Django backend
â”‚   â”œâ”€â”€ aws_llm/                 # LLM integration
â”‚   â”‚   â”œâ”€â”€ views.py             # API endpoints
â”‚   â”‚   â”œâ”€â”€ serializers.py       # Data serialization
â”‚   â”‚   â”œâ”€â”€ urls.py              # URL routing
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ llm_wrapper.py   # LLM client
â”‚   â”œâ”€â”€ main/                    # Main Django app
â”‚   â”œâ”€â”€ settings/                # Django settings
â”‚   â””â”€â”€ manage.py                # Django management
â”œâ”€â”€ docker/                      # Docker configuration
â”œâ”€â”€ package.json                 # Frontend dependencies
â”œâ”€â”€ pyproject.toml              # Backend dependencies
â””â”€â”€ README.md                   # This file
```

## ğŸ› ï¸ Installation & Setup

### Prerequisites

- Node.js 22+
- Python 3.13+
- pnpm (recommended) or npm

### Frontend Setup

1. **Install dependencies**:

   ```bash
   pnpm install
   ```

2. **Start development server**:

   ```bash
   pnpm dev
   ```

3. **Open in browser**: [http://localhost:3000](http://localhost:3000)

### Backend Setup

1. **Create virtual environment**:

   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

2. **Install dependencies**:

   ```bash
   pip install -r requirements.txt
   # or using uv (recommended)
   uv sync
   ```

3. **Run migrations**:

   ```bash
   python manage.py migrate
   ```

4. **Start development server**:

   ```bash
   python manage.py runserver
   ```

5. **API Documentation**: [http://localhost:8000/api/docs/](http://localhost:8000/api/docs/)

## ğŸ¨ Design System

### Color Palette

- **Primary Blue**: `#2176FF` - Main accent color
- **Background**: White with subtle gradients
- **Text**: Dark gray/black for readability
- **Accents**: Green for success, red for errors

### Typography

- **Font**: System font stack (San Francisco, Segoe UI, etc.)
- **Weights**: Regular (400), Medium (500), Bold (700)
- **Hierarchy**: Clear text sizing and spacing

### Components

- **Rounded Corners**: 2xl (16px) for modern look
- **Shadows**: Subtle depth and layering
- **Animations**: 300ms smooth transitions
- **Spacing**: Generous padding and margins

## ğŸ”§ Configuration

### Environment Variables

Create a `.env.local` file in the root directory:

```env
# Frontend
NEXT_PUBLIC_API_URL=http://localhost:8000

# Backend
SECRET_KEY=your-secret-key
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1
```

### API Configuration

The backend is configured to work with an external LLM service. Update the LLM endpoint in `src/aws_llm/utils/llm_wrapper.py`:

```python
# Update this URL to your LLM service
LLM_ENDPOINT = "http://your-llm-service:8080/v1/chat/completions"
```

## ğŸš€ Deployment

### Frontend (Vercel)

1. Connect your GitHub repository to Vercel
2. Configure environment variables
3. Deploy automatically on push to main

### Backend (Docker)

1. Build the Docker image:

   ```bash
   docker build -f docker/prod/dockerfile.prod -t pchat-backend .
   ```

2. Run with Docker Compose:
   ```bash
   docker-compose -f docker/prod/docker-compose.prod.yml up -d
   ```

## ğŸ“š API Documentation

### Endpoints

#### POST `/api/aws-llm/chat/`

Send a message to the AI assistant.

**Request Body**:

```json
{
  "message": "Hello, how are you?",
  "model": "gemma2:2b",
  "stream": false
}
```

**Response**:

```json
{
  "response": "Hello! I'm doing well, thank you for asking.",
  "model_used": "gemma2:2b",
  "timestamp": "2024-01-01T12:00:00Z",
  "success": true
}
```

### Interactive API Documentation

Visit [http://localhost:8000/api/docs/](http://localhost:8000/api/docs/) for interactive API documentation.

## ğŸ§ª Development

### Running Tests

```bash
# Frontend tests
pnpm test

# Backend tests
python manage.py test
```

### Code Quality

```bash
# Linting
pnpm lint

# Type checking
pnpm type-check
```

### Building for Production

```bash
# Frontend
pnpm build

# Backend
python manage.py collectstatic
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit your changes: `git commit -m 'Add amazing feature'`
4. Push to the branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Next.js](https://nextjs.org/) for the amazing React framework
- [Django](https://djangoproject.com/) for the robust backend framework
- [Tailwind CSS](https://tailwindcss.com/) for the utility-first CSS framework
- [TanStack Query](https://tanstack.com/query) for server state management

## ğŸ“ Support

If you have any questions or need help, please open an issue on GitHub or contact the development team.

---

**Built with â¤ï¸ using Next.js, Django, and modern web technologies.**
