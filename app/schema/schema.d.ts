/**
 * This file was auto-generated by openapi-typescript.
 * Do not make direct changes to the file.
 */

export interface paths {
    "/api/aws-llm/chat/": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        get?: never;
        put?: never;
        /**
         * Send a message to the AI assistant
         * @description Send a message to the AI assistant and receive a response using AWS-hosted LLM
         */
        post: operations["chat_response"];
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
    "/api/aws-llm/chat/history/": {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        /**
         * Get chat history
         * @description Get chat history for a user
         */
        get: operations["aws_llm_chat_history_retrieve"];
        put?: never;
        post?: never;
        delete?: never;
        options?: never;
        head?: never;
        patch?: never;
        trace?: never;
    };
}
export type webhooks = Record<string, never>;
export interface components {
    schemas: {
        /** @description Serializer for chat conversations */
        ChatConversation: {
            readonly id: number;
            readonly messages: string;
            /** Format: date-time */
            readonly created_at: string;
            user: number;
        };
        /** @description Serializer for incoming chat requests */
        ChatRequestRequest: {
            /** @description The user's message to the AI assistant (legacy field) */
            message?: string;
            /**
             * @description The AI model to use for the response
             * @default gemma2:2b
             */
            model: string;
            /**
             * @description Whether to stream the response
             * @default false
             */
            stream: boolean;
        };
        /** @description Serializer for chat responses */
        ChatResponse: {
            /** @description The AI assistant's response */
            response: string;
            /** @description The model that was used to generate the response */
            model_used: string;
            /**
             * Format: date-time
             * @description When the response was generated
             */
            timestamp: string;
            /** @description Whether the request was successful */
            success: boolean;
        };
        /** @description Serializer for error responses */
        ErrorResponse: {
            /** @description Error message */
            error: string;
            /** @description Additional error details */
            details?: string;
            /**
             * Format: date-time
             * @description When the error occurred
             */
            timestamp: string;
        };
    };
    responses: never;
    parameters: never;
    requestBodies: never;
    headers: never;
    pathItems: never;
}
export type $defs = Record<string, never>;
export interface operations {
    chat_response: {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        requestBody?: {
            content: {
                "application/json": components["schemas"]["ChatRequestRequest"];
                "application/x-www-form-urlencoded": components["schemas"]["ChatRequestRequest"];
                "multipart/form-data": components["schemas"]["ChatRequestRequest"];
            };
        };
        responses: {
            200: {
                headers: {
                    [name: string]: unknown;
                };
                content: {
                    "application/json": components["schemas"]["ChatResponse"];
                };
            };
            400: {
                headers: {
                    [name: string]: unknown;
                };
                content: {
                    "application/json": components["schemas"]["ErrorResponse"];
                };
            };
            500: {
                headers: {
                    [name: string]: unknown;
                };
                content: {
                    "application/json": components["schemas"]["ErrorResponse"];
                };
            };
        };
    };
    aws_llm_chat_history_retrieve: {
        parameters: {
            query?: never;
            header?: never;
            path?: never;
            cookie?: never;
        };
        requestBody?: never;
        responses: {
            200: {
                headers: {
                    [name: string]: unknown;
                };
                content: {
                    "application/json": components["schemas"]["ChatConversation"];
                };
            };
            404: {
                headers: {
                    [name: string]: unknown;
                };
                content: {
                    "application/json": components["schemas"]["ErrorResponse"];
                };
            };
        };
    };
}
